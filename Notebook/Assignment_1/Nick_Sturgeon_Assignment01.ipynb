{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAvZqXUN7zj5"
   },
   "source": [
    "**HOMEWORK 1**\n",
    "\n",
    "Assigned: September 02 (3:00PM)\n",
    "\n",
    "Due: September 16 (11:59PM midnight)\n",
    "\n",
    "This assignment consists four questions. Two of them require you to generate some Python code.\n",
    "\n",
    "--\n",
    "\n",
    "You are expected to:\n",
    "\n",
    "(1) clone the notebook to your own Google Drive;\n",
    "\n",
    "(2) enter your answer and code to the cloned notebook directly; and\n",
    "\n",
    "(3) upload the shareable link of your notebook to Canvas (as your homework submission).\n",
    "(4) if using JupyterLab Notebook, please upload the ipynb file directly\n",
    "(5) Alternatively, you can upload pdf of the notebook with all the code and outputs visible\n",
    "\n",
    "--\n",
    "\n",
    "**Late submission is only possible within two days, and a deduction of 5% per day will be applied.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCHVLhYF-Fb6"
   },
   "source": [
    "**PROBLEM 1 [30 points]**\n",
    "\n",
    "**A [20pt].** Use information gain to build a decision tree that predicts the value of the target feature **PLAY** based on the values of other input features such as **ACE**, **TEN**, and **FIRST_MOVE**. Please use the training data provided below and shows the steps of your calculations.\n",
    "\n",
    "ACE | TEN | FIRST_MOVE | PLAY\n",
    "----- | ----- | ----- | -----\n",
    "false | false | false | stand\n",
    "true | false | true | hit\n",
    "true | true | false | hit\n",
    "true | true | true | stand\n",
    "\n",
    "Suppose that a tree is considered not optimal if there is another tree that achieves the same classification error on the training data but has smaller depth.\n",
    "\n",
    "**B [5pt].** Is the tree found in the example above optimal? Explain why or why not.\n",
    "\n",
    "**C [5pt].** If it is not optimal, draw the optimal tree as well. You can draw it by hand on a piece of paper, upload it somewhere with a publicly shareable link and load it on this notebook.\n",
    "\n",
    "**Note that: if the link is not publicly accessible, the TA will not be able to load it and grade this part of your submission.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer A:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qRQpPCIvDi_a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00       1.0\n",
      "        True       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "play_df = pd.read_csv(\"play.csv\")\n",
    "\n",
    "play_df.head()\n",
    "\n",
    "sns.pairplot(play_df, hue='PLAY')\n",
    "\n",
    "X = play_df[['ACE','TEN','FIRST_MOVE','PLAY']].values\n",
    "y = play_df['PLAY'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, random_state=1)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)  \n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "prediction\n",
    "\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer B:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer C:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XA7SnE6oDoWR"
   },
   "source": [
    "**PROBLEM 2 [10 points]**\n",
    "\n",
    "Express the concept **PLAY**=**Hit** learned by all the trees found in **PROBLEM 1** in terms of logical if-then rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4iQlvy7EUt4"
   },
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMzWx6DyEW94"
   },
   "source": [
    "**PROBLEM 3 [30 points]**\n",
    "\n",
    "**A [10pt].** How does the computational complexity of the $k$-nearest neighbors algorithm grow with the no. of training samples $n$, neighborhood size $k$ and the no. of dimension $d$? Do explain the answer.\n",
    "\n",
    "**B [20pt].** Fill in the code template below to complete the $k$-nearest neighbors algorithm and its evaluation on the Iris dataset.\n",
    "\n",
    "In particular, run $10$ evaluations. In each evaluation:\n",
    "\n",
    "*1.* Randomly partitions the dataset: 80% for train set and 20% for test set.\n",
    "\n",
    "*2.* Compute the train and test accuracy of KNN with k = 1, 2, ..., 30.\n",
    "\n",
    "Finally, compute the averaged train and test accuracy of KNN with k = 1, 2, ..., 30 over the above 10 independent evaluations. Plot the train and test accuracy curves. What is the (empirically) best value for k?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBgyKww70Rbx"
   },
   "source": [
    "**ANSWER:** (provide text answer for PART A and PART B here, fill in necessary code to complete the code block below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4zL0xgGAGmFs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# K-nearest neighbor implementation\n",
    "\n",
    "def distance(a, b):\n",
    "    # both a and b are numpy arrays of shape (d,)\n",
    "    # fill in the code to compute their Euclidean distance\n",
    "    pass # remove this once the code has been filled in\n",
    "\n",
    "def update(neighbors_and_distance, x_index, proximity, k = 10):\n",
    "    # fill in the code to update neighbors_and_distance according to how it is organized (which is also your choice)\n",
    "    pass # remove this once the code has been filled in\n",
    "\n",
    "def find_nearest_neighbor(x_test, X, k = 10):\n",
    "    neighbors_and_distance = []  # decide how to organize this such that it will work in tandem with the update function below -- it does not have to be a list\n",
    "    for i in range(X.shape[0]):\n",
    "        x_candidate = X[i]\n",
    "        proximity = distance(x_candidate, x_test)  # compute the Euclidean distance between two data points\n",
    "        neighbors_and_distance = update(neighbors_and_distance, i, proximity, k = k)  # this needs to be implemented in tandem with how neighbors_and_distance is organized\n",
    "    # fill in whatever else necessary here to extract a list of indices corresponding to the k nearest neighbors\n",
    "    pass # remove this once the code has been filled in\n",
    "\n",
    "def dominant_label(neighbors, Y):\n",
    "    # fill in the code to find the dominant label among the neighborhood\n",
    "    pass # remove this once the code has been filled in\n",
    "\n",
    "def predict(x_test, X, Y, k = 10): # x_test is the test input, X and Y are training input and output respectively\n",
    "    # X is expected to be a numpy array of shape (n, d), Y is of shape (n,) and x_test is of shape (d,)\n",
    "    neighbors = find_nearest_neighbor(x_test, X, k = k)  # return a list of indices\n",
    "    return dominant_label(neighbors, Y)  # return the dominant label among the neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EyNSp2PuFrXA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1663.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# evaluate K-NN\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# evaluation code\n",
    "\n",
    "def evaluate(X_test, Y_test, X_train, Y_train, k):\n",
    "    # fill in the code to make prediction at X_test, compare that to Y_test and compute the prediction accuracy\n",
    "    pass # return the prediction accuracy\n",
    "\n",
    "# load iris data\n",
    "\n",
    "iris = load_iris()\n",
    "X_all = iris.data\n",
    "Y_all = iris.target\n",
    "\n",
    "max_k, n_simulation = 30, 10\n",
    "\n",
    "test_avg_acc, train_avg_acc = [0] * max_k, [0] * max_k\n",
    "\n",
    "for i in trange(n_simulation):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size = 0.2, random_state = i * 1000)  # randomly split data\n",
    "    # fill in the code to compute test_acc and train_acc of KNN using the above train/test partition\n",
    "    # fill in the code to update the running average in test_avg_acc and train_avg_acc\n",
    "\n",
    "# fill in the code to plot the test and train accuracy curves against the neighborhood size k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YIWk1AxO2uM"
   },
   "source": [
    "**PROBLEM 4 [30pts]**\n",
    "\n",
    "The purpose of this programming assignment is to get you familiar with building decision trees, loading data, and evaluating a classifier's predictive accuracy. To complete the assignment, you will:\n",
    "\n",
    "(1) load a dataset (5pt);\n",
    "\n",
    "(2) enhance the decision tree code to specify a depth limit (10pt); and\n",
    "\n",
    "(3) compare the classification accuracies of a decision tree with no depth limit versus that of a decision tree with a depth limit ( = 1,2, ..., 5) on a random selection of train and test data (10pt); and\n",
    "\n",
    "(4) answer the questions that reflect on the performance of your classifier (5pt).\n",
    "\n",
    "--\n",
    "\n",
    "**Datasets.** Use the attached Tic-Tac-Toe dataset for the assignment. This dataset contains binary classification of tic-tac-toe endgames, classified as \"true\" if the game is a \"win for x\". You may use any of the methods we discussed in class or any other method you find available to load the dataset. This dataset contains many instances (one instance per row) and many attributes. For each instance, the target variable is in the last column. The remaining columns represent the input features of the data point.\n",
    "\n",
    "**Evaluation.** Add code to evaluate the classifier's accuracy. To do this, you will need to randomly split the dataset into training data (the first 700 data points) and testing data (the rest of the data points). Train (build) the decision tree on the training data. Then use the tree to predict the label for each test data point. To compute accuracy, compute (and report) the fraction of test data points that are predicted correctly by the decision tree classifier.\n",
    "\n",
    "**Prune.** Add the ability to limit the depth of the decision tree.\n",
    "\n",
    "**Questions.** How did the performance change when you added a depth limit = 1, 2, ..., 5? Why do you think the tree performed differently in this case? Is using the first 700 data points for training and the rest for testing an unbiased mechanism for evaluating performance? Explain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7VaW2vqgOh9Z"
   },
   "outputs": [],
   "source": [
    "# Below is a working code of a vanilla decision tree learning with NO depth limit mechanism -- You are supposed to add this mechanism to the code\n",
    "# Here, we assume discrete features. The stopping condition for tree generation is when all examples have the same class, or there are no more features to split on (in which case, use the majority class).\n",
    "# If a split yields no examples for a particular feature value, then the classification is based on the parent's majority class.\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, majClass):\n",
    "        self.split_feature = -1 # -1 indicates leaf node\n",
    "        self.children = {} # dictionary of {feature_value: child_tree_node}\n",
    "        self.majority_class = majClass\n",
    "\n",
    "def build_tree(examples):\n",
    "    if len(examples) == 0:\n",
    "        return None\n",
    "    # collect sets of values for each feature index, based on the examples\n",
    "    features = {}\n",
    "    for feature_index in range(len(examples[0]) - 1):\n",
    "        features[feature_index] = set([example[feature_index] for example in examples])\n",
    "    return expand(examples, features)\n",
    "\n",
    "def expand(examples, features):\n",
    "    tree_node = TreeNode(majority_class(examples))\n",
    "    # if no examples for this node, then return leaf node predicting majority class\n",
    "    if len(examples) == 0:\n",
    "      return tree_node\n",
    "    # if examples all have same class, then return leaf node predicting this class\n",
    "    if same_class(examples):\n",
    "        return tree_node\n",
    "    # if no more features to split on, then return leaf node predicting majority class\n",
    "    if not features:\n",
    "        return tree_node\n",
    "    # split on best feature and recursively generate children\n",
    "    best_feature_index = best_feature(features, examples)\n",
    "    tree_node.split_feature = best_feature_index\n",
    "    remaining_features = features.copy()\n",
    "    remaining_features.pop(best_feature_index)\n",
    "    for feature_value in features[best_feature_index]:\n",
    "        split_examples = filter_examples(examples, best_feature_index, feature_value)\n",
    "        tree_node.children[feature_value] = expand(split_examples, remaining_features)\n",
    "    return tree_node\n",
    "\n",
    "def majority_class(examples):\n",
    "    if len(examples) == 0:\n",
    "      return 'positive'   # hard coded for this dataset\n",
    "    classes = [example[-1] for example in examples]\n",
    "    return max(set(classes), key = classes.count)\n",
    "\n",
    "def same_class(examples):\n",
    "    classes = [example[-1] for example in examples]\n",
    "    return (len(set(classes)) == 1)\n",
    "\n",
    "def best_feature(features, examples):\n",
    "    # Return index of feature with lowest entropy after split\n",
    "    best_feature_index = -1\n",
    "    best_entropy = 2.0 # max entropy = 1.0\n",
    "    for feature_index in features:\n",
    "        se = split_entropy(feature_index, features, examples)\n",
    "        if se < best_entropy:\n",
    "            best_entropy = se\n",
    "            best_feature_index = feature_index\n",
    "    return best_feature_index\n",
    "\n",
    "def split_entropy(feature_index, features, examples):\n",
    "    # Return weighted sum of entropy of each subset of examples by feature value.\n",
    "    se = 0.0\n",
    "    for feature_value in features[feature_index]:\n",
    "        split_examples = filter_examples(examples, feature_index, feature_value)\n",
    "        se += (float(len(split_examples)) / float(len(examples))) * entropy(split_examples)\n",
    "    return se\n",
    "\n",
    "def entropy(examples):\n",
    "    classes = [example[-1] for example in examples]\n",
    "    classes_set = set(classes)\n",
    "    class_counts = [classes.count(c) for c in classes_set]\n",
    "    e = 0.0\n",
    "    class_sum = sum(class_counts)\n",
    "    for class_count in class_counts:\n",
    "        if class_count > 0:\n",
    "            class_frac = float(class_count) / float(class_sum)\n",
    "            e += (-1.0)* class_frac * math.log(class_frac, 2.0)\n",
    "    return e\n",
    "\n",
    "def filter_examples(examples, feature_index, feature_value):\n",
    "    # Return subset of examples with given value for given feature index.\n",
    "    return list(filter(lambda example: example[feature_index] == feature_value, examples))\n",
    "\n",
    "def print_tree(tree_node, depth = 1):\n",
    "    indent_space = depth * \"  \"\n",
    "    if tree_node.split_feature == -1: # leaf node\n",
    "        print(indent_space + \"class: \" + tree_node.majority_class)\n",
    "    else:\n",
    "        for feature_value in tree_node.children:\n",
    "            print(indent_space + \"feature \" + str(tree_node.split_feature) + \" == \" + feature_value)\n",
    "            child_node = tree_node.children[feature_value]\n",
    "            if child_node:\n",
    "                print_tree(child_node, depth+1)\n",
    "            else:\n",
    "                # no child node for this value, so use majority class of parent (tree_node)\n",
    "                print(indent_space + \"  \" + \"class\" + \": \" + tree_node.majority_class)\n",
    "\n",
    "def classify(tree_node, instance):\n",
    "    if tree_node.split_feature == -1:\n",
    "        return tree_node.majority_class\n",
    "    child_node = tree_node.children[instance[tree_node.split_feature]]\n",
    "    if child_node:\n",
    "        return classify(child_node, instance)\n",
    "    else:\n",
    "        return tree_node.majority_class\n",
    "\n",
    "# Now, set up the driving code to evaluate the above decision tree algorithm below\n",
    "\n",
    "# Fill in code to load data here\n",
    "\n",
    "# Call build_tree to generate a tree -- you must understand the above code to know what is to be included in \"examples\" which is passed as input to the build_tree function\n",
    "\n",
    "# Add code to evaluate the tree\n",
    "\n",
    "# Once the above are completed. Think about how to modify the above code to limit the depth of the tree.\n",
    "\n",
    "# Re-generate the tree and evaluate again with limit = 1, 2, 3, 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cdjOxSKjEu2r"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evTrgfDMElcI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtMOX5_32AAw"
   },
   "source": [
    "**ANSWER:** Provide answers to the questions that reflect on the performance of your classifier here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
